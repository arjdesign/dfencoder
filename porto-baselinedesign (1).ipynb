{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dfencoder\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import pandas as pd\n",
    "from dfencoder import AutoEncoder\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"C:/Users/Arjun/kaggle/porto-seguro/train.csv\"\n",
    "test_path = \"C:/Users/Arjun/kaggle/porto-seguro/test.csv\"\n",
    "submission_path = \"C:/Users/Arjun/kaggle/porto-seguro/sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = ['id']\n",
    "binary = []\n",
    "cats = []\n",
    "\n",
    "for col in train.columns:\n",
    "    if 'calc' in col:\n",
    "        to_remove.append(col)\n",
    "    elif 'bin' in col:\n",
    "        binary.append(col)\n",
    "    elif 'cat' in col:\n",
    "        cats.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop undesired columns.\n",
    "X_train = train.drop(columns=to_remove+['target'])\n",
    "Y_train = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = test.drop(columns=to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do our one-hot encoding, naming new columns.\n",
    "for cat in cats:\n",
    "    ohe = pd.get_dummies(X_test[cat])\n",
    "    ohe_columns = [cat + \"_ohe_\" + str(i) for i in ohe.columns]\n",
    "    ohe.columns = ohe_columns\n",
    "    X_test = pd.concat([X_test, ohe], axis=1)\n",
    "\n",
    "    ohe = pd.get_dummies(X_train[cat])\n",
    "    ohe.columns = ohe_columns\n",
    "    X_train = pd.concat([X_train, ohe], axis=1)\n",
    "\n",
    "    binary += ohe_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#set all column types to numeric\n",
    "for col in X_train.columns:\n",
    "    if col in binary:\n",
    "        X_train[col] = X_train[col].astype(int)\n",
    "        X_test[col] = X_test[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#our dataframe should have 221 columns, all numeric.\n",
    "%time\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#validation sample\n",
    "X_val = X_test.sample(frac=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the encoded test set for later\n",
    "X_test.to_hdf('X_test.h5', key='stage', mode='w')\n",
    "\n",
    "\n",
    "\n",
    "#delete references to memory-consuming data\n",
    "import gc\n",
    "\n",
    "del train\n",
    "del test\n",
    "del X_test\n",
    "\n",
    "#remove objects from memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use torch.cuda.empty_cache()?\n",
    "\n",
    "One case where you would want to use it though is if you use cudnn benchmark mode (torch.backends.cudnn.benchmark=True), then you can add one after the very first forward of the program that you do. As the benchmark mode can allocate large memory blocks during the very first forward to test algorithms and that wonâ€™t be good latter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dfencoder allows us to specify scaling behavior per-feature;\n",
    "#this dictionary will specify not to scale one-hot encoded features.\n",
    "scaler_spec = {ft:None for ft in binary}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation on Hold-out set\n",
    "\n",
    "This is the unsupervised learning. EVen here it is good idea to split train/val set during training. This will help to fune tune the model and avoid overfitting. Holdout : 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = .2, random_state =42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = AutoEncoder(\n",
    "#imput and output layers are implicit\n",
    "    encoder_layers = [1500, 1500, 1500],\n",
    "    decoder_layers = [],\n",
    "    lr = 2.8e-3,\n",
    "    batch_size = 128,\n",
    "    activation = 'relu',\n",
    "    lr_decay =.995,\n",
    "    swap_p = 0.2,\n",
    "    #swap noise\n",
    "    # \"scalar_spec\" do not scale following cols\n",
    "    #when you put gauss_rank, you are scaling the specific columns. \n",
    "    scaler = 'gauss_rank',\n",
    "    optimizer ='adam',\n",
    "    verbose = False,\n",
    "    logger = 'ipynb',\n",
    "    progress_bar = True,\n",
    "    device = torch.device(\"cuda:0\")   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.fit(X_train, val=X_val, epochs=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = encoder.get_deep_stack_features(X_val)\n",
    "print(z.shape)\n",
    "print(z[0, :])\n",
    "del z\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModel ((torch.nn.Module)):\n",
    "    def __Init__ ( self, *args, **kwargs):\n",
    "        # we are calling __init__ of parent class. i.e torch.nn.module\n",
    "        super(ClassifierModel, self).__init__(*args, **kwargs)\n",
    "        self.input_dropout = torch.nn.Dropout(.1)\n",
    "        self.input_layer = torch.nn.Linear(4500.1000)\n",
    "        self.dropout = troch.nn.Dropout(.5)\n",
    "        self.dense1 = torch.nn.Linear(1000,10000)\n",
    "        # in keras you set one value for dense egL Dense(128, activation ='relu)\n",
    "        #alternatively in pytorch you set torch.nn.Linear(128, output_value)\n",
    "        self.dense2 = torch.nn.Linear(1000,1000)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.output = torch.nn.Linear(1000,1)\n",
    "        self.sigmoid = torch.nn.Sigmoid\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.input_dropout(x)\n",
    "            \n",
    "            #layer1\n",
    "            x = self.dropout(self.relu(self.input_layer(x)))\n",
    "           \n",
    "            #layer 2\n",
    "            x = self.dropout(self.relu(self.dense1(x)))\n",
    "            \n",
    "            #layer 3\n",
    "            x  = self.dropout(self.relu(self.dense2(x)))\n",
    "            \n",
    "            #output layer\n",
    "            x = self.sigmoid(self.output(x))\n",
    "            return x\n",
    "        \n",
    "#create classifier object\n",
    "\n",
    "classifier = ClassifierModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(\n",
    "    classifier.parameters(),\n",
    "    lr=1e-4,\n",
    "    weight_decay=.05,\n",
    "    \n",
    ")\n",
    "\n",
    "decay = torch.optim.lr_scheduler.ExponentialLR(optim, .995)\n",
    "\n",
    "loss = torch.nn.modules.loss.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifier.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def do_step(classifier, optim, z, target, loss):\n",
    "    pred = classifier(z)\n",
    "    target = torch.tensor(target).float().reshape(-1, 1).to(\"cuda:0\")\n",
    "    loss_ = loss(pred, target)\n",
    "    amnt = loss_.item()\n",
    "    loss_.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "    return amnt\n",
    "\n",
    "def do_evaluation(classifier, z, target, loss):\n",
    "    with torch.no_grad():\n",
    "        pred = classifier(z)\n",
    "        target_ = torch.tensor(target).float().reshape(-1, 1).to(\"cuda:0\")\n",
    "        loss_ = loss(pred, target_)\n",
    "        return loss_.item()\n",
    "  \n",
    "batch_size =128\n",
    "n_updates = (len(X_train)//batch_size) + 1\n",
    "\n",
    "n_megabatches = 8\n",
    "n_epochs = 150\n",
    "\n",
    "n_rows = len(X_train)\n",
    "\n",
    "res = n_rows/n_megabatches #4651/8\n",
    "batches_per_megabatch = (res // batch_size) + 1 # 581 /128 =4 (floor division)\n",
    "megabatch_size = batches_per_megabatch * batch_size # 4*128 =512\n",
    "final_batch_size = n_rows - (n_megabatches - 1) * megabatch_size #4651 - 7 = 4644\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    with tqdm.tqdm(total=n_updates) as bar:\n",
    "        for j in range(n_megabatches):\n",
    "            mega_start = int((j) * megabatch_size) #512\n",
    "            mega_stop = int((j+1) * megabatch_size) #1024\n",
    "            slc = X_train.iloc[mega_start:mega_stop] #from 512 to 1024\n",
    "            z = encoder.get_deep_stack_features(slc) #get z from 512 to 1024\n",
    "            target_slc = Y_train.iloc[mega_start:mega_stop].values\n",
    "            if j == (n_megabatches-1):\n",
    "                steps = final_batch_size/batch_size\n",
    "            #if final_batch_size % batch_size != 0:\n",
    "                #steps = steps +1\n",
    "            else:\n",
    "                steps = int(batches_per_megabatch)\n",
    "            steps = int(steps)\n",
    "            for i in range(steps):\n",
    "                step = i\n",
    "                start = int((step) * batch_size)\n",
    "                stop = int((step+1) * batch_size)\n",
    "                in_ = z[start:stop]\n",
    "                target = target_slc[start:stop]\n",
    "                do_step(classifier, optim, in_, target, loss)\n",
    "                bar.update(1)\n",
    "                bce_loss = do_evaluation(classifier, in_, target, loss)\n",
    "            decay.step()\n",
    "            \n",
    "    del z\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print('validation loss: ', round(bce_loss, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_hdf('X_test.h5')\n",
    "test = pd.read_csv(test_path)\n",
    "ids = test['id'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are moving the tensor to GPU\n",
    "def do_inference(encoder, classifier, data):\n",
    "    #z = torch.tensor(encoder.get_deep_stack_features(data)).to(\"cuda:0\")\n",
    "    #or you can do torch.tensor(encoder.get_deep_stack_features(data)).cuda()\n",
    "    z = torch.tensor(encoder.get_deep_stack_features(data)).cuda()\n",
    "    output = classifier(z)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_batch_size = 2048\n",
    "n_batches = (len(X_test)//eval_batch_size) + 1\n",
    "#n_batches = 10\n",
    "\n",
    "out = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm.trange(n_batches):\n",
    "        start = i * eval_batch_size\n",
    "        stop = (i+1) * eval_batch_size\n",
    "        slc = X_test.iloc[start:stop]\n",
    "        res = do_inference(encoder, classifier, slc)\n",
    "        out.append(res.reshape(-1))\n",
    "        clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# we are taking vec tensor to CPU using cpu()\n",
    "\n",
    "result = np.concatenate([vec.cpu().numpy() for vec in out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format data for kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submit = pd.DataFrame()\n",
    "to_submit['id'] = ids\n",
    "to_submit['target'] = result\n",
    "\n",
    "to_submit.to_csv('submission.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
